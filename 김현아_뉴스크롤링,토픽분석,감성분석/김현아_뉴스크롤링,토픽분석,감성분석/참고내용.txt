BeautifulSoup을 이용한 네이버 뉴스 crawler를 작성해 신입취업으로 검색했을때 나오는 결과물을 관련도순으로 수집
수집한 데이터를 json 파일로 저장
감성분석 모델 구축은 깃허브의 nsmc 네이버 영화 리뷰 데이터세트 이용. 부정감성은 0, 금정감성은 1로 정리되어있음
정규표현식을 이용해서 한글 이외의 문자를 공백으로 변환
텍스트 마이닝의 모듈들을 모아놓은 gensim 패키지를 사용함. 사이킷런을 사용할때보다 객체 생성 및 실행을 한번에 할 수 있어서 효과적.
문서에 들어가있는 단어들의 분포를 근거로 패턴을 찾아서 토픽 그룹을 만들어줌
pyLDAvis 를 이용해서 시각화 해줌
시각화 화면에서 동그란건 클러스터의 분포 위치를 보여줌
클러스터를 선택하면 오른쪽에서 해당하는 분포를 보여주고 각 클러스터마다 다른 상위 단어를 볼 수 있음
토픽의 비율을 비교할 수 있고 특정 클러스터에 특화된 단어를 보고싶다면 람다값을 0.2 이하로 줄여서 확인할 수 있음
단어를 클릭하면 그 단어가 분포된 클러스터가 나오고 상대적인 중요도를 같이 볼 수 있음

이렇게 얻은 데이터를 표로 정리.

토픽분석결과로 얻은 주요 단어들로 토픽 레이블을 만들고 시각화한 데이터에서 해당되는 토픽을 찾아 번호로 연결
시각화한 데이터에서 얻은 특화단어 15개를 정리하고 결과적으로 얻은 토픽들을 정리해 최종 토픽 레이블을 도출
